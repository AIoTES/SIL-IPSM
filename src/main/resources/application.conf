akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  actor {
    deployment {
      /semantic-router {
        router = smallest-mailbox-pool
        nr-of-instances = 5
        pool-dispatcher {
          # Dispatcher is the name of the event-based dispatcher
          type = PinnedDispatcher
          # What kind of ExecutionService to use
          executor = "thread-pool-executor"
          # Configuration for the thread pool
          thread-pool-executor {
            core-pool-size-min = 5
            core-pool-size-max = 5
          }
        }

      }
    }

  }
  # Properties for akka.kafka.ConsumerSettings can be
  # defined in this section or a configuration section with
  # the same layout.
  kafka {
    delete.topic.enable = true
    auto.create.topics.enable = true
    consumer {
      # Tuning property of scheduled polls.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that blocking of the thread that
      # is executing the stage will be blocked.
      poll-timeout = 50ms

      # The stage will be await outstanding offset commit requests before
      # shutting down, but if that takes longer than this timeout it will
      # stop forcefully.
      stop-timeout = 30s

      # How long to wait for `KafkaConsumer.close`
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      commit-timeout = 15s

      # If the KafkaConsumer can't connect to the broker the poll will be
      # aborted after this timeout. The KafkaConsumerActor will throw
      # org.apache.kafka.common.errors.WakeupException, which can be handled
      # with Actor supervision strategy.
      wakeup-timeout = 10s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
      }
    }
    producer {
      # Tuning parameter of how many sends that can run in parallel.
      parallelism = 100

      # How long to wait for `KafkaProducer.close`
      close-timeout = 60s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producer stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
      }
      offset.storage = "kafka"
      dual.commit.enabled = false
      auto.commit.enable = true
    }
  }
}

http {
  port = "8080"
  port = ${?IPSM_REST_PORT}
  host = "0.0.0.0"
  host = ${?IPSM_REST_HOST}
}

ipsm-db-sqlite = {
  driver = "slick.driver.SQLiteDriver$"
  db {
    initializationFailFast = yes
    url = "jdbc:sqlite:/sqlite/ipsm.db"
    url = ${?IPSM_SQLITE_URL}
    driver = org.sqlite.JDBC
  }
}

ipsm-kafka = {
  host = "127.0.0.1"
  host = ${?IPSM_KAFKA_HOST}
  port = 9092
  port = ${?IPSM_KAFKA_PORT}
}
